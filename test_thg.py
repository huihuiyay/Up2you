"""
THGä¼˜åŒ–å¿«é€ŸéªŒè¯è„šæœ¬
æµ‹è¯•THGè°ƒåº¦å™¨çš„åŸºæœ¬åŠŸèƒ½å’Œç»Ÿè®¡
"""

import torch
from diffusers import DDPMScheduler
from up2you.schedulers.scheduling_thg import TortoiseHareGuidanceScheduler


def test_thg_basic():
    """æµ‹è¯•THGè°ƒåº¦å™¨åŸºæœ¬åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•1: THGè°ƒåº¦å™¨åŸºæœ¬åŠŸèƒ½")
    print("=" * 80)

    # åˆ›å»ºåŸºç¡€è°ƒåº¦å™¨
    base_scheduler = DDPMScheduler(
        num_train_timesteps=1000,
        beta_start=0.00085,
        beta_end=0.012,
    )

    # åŒ…è£…ä¸ºTHGè°ƒåº¦å™¨
    thg_scheduler = TortoiseHareGuidanceScheduler.from_scheduler(
        base_scheduler,
        guidance_update_interval=3,
    )

    print(f"âœ“ THGè°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ")
    print(f"  å¼•å¯¼æ›´æ–°é—´éš”: {thg_scheduler.guidance_update_interval}")

    # æ¨¡æ‹Ÿ50æ­¥æ¨ç†
    num_steps = 50
    batch_size = 2
    latent_dim = 4
    height, width = 64, 64

    # é‡ç½®ç»Ÿè®¡
    thg_scheduler.reset_statistics()

    for step in range(num_steps):
        # æ¨¡æ‹Ÿå™ªå£°é¢„æµ‹
        noise_cond = torch.randn(batch_size, latent_dim, height, width)
        noise_uncond = torch.randn(batch_size, latent_dim, height, width) if step % 3 == 0 else None

        # ä½¿ç”¨THGè®¡ç®—
        noise_pred, updated = thg_scheduler.compute_noise_pred_with_thg(
            noise_cond,
            noise_uncond,
            guidance_scale=3.0,
            step_index=step,
        )

        if step < 5 or step % 10 == 0:
            update_status = "âœ“ æ›´æ–°å¼•å¯¼" if updated else "â†’ å¤ç”¨ç¼“å­˜"
            print(f"  æ­¥éª¤ {step:2d}: {update_status}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = thg_scheduler.get_statistics()
    print(f"\nç»Ÿè®¡ç»“æœ:")
    print(f"  æ€»NFE: {stats['total_nfe']}")
    print(f"  èŠ‚çœNFE: {stats['saved_nfe']}")
    print(f"  æ•ˆç‡æå‡: {stats['efficiency']}")

    # éªŒè¯NFEå‡å°‘
    expected_nfe = num_steps + (num_steps // 3)  # æ¡ä»¶ + éƒ¨åˆ†æ— æ¡ä»¶
    assert stats['total_nfe'] <= num_steps * 2, "NFEåº”è¯¥å°‘äºæ ‡å‡†æ¨ç†çš„2å€"
    print(f"\nâœ… æµ‹è¯•1é€šè¿‡: NFEä»{num_steps*2}é™è‡³{stats['total_nfe']}")


def test_thg_intervals():
    """æµ‹è¯•ä¸åŒTHGé—´éš”çš„NFE"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: ä¸åŒTHGé—´éš”çš„æ•ˆç‡å¯¹æ¯”")
    print("=" * 80)

    base_scheduler = DDPMScheduler(num_train_timesteps=1000)
    num_steps = 50

    results = []
    for interval in [1, 2, 3, 4, 5]:
        thg_scheduler = TortoiseHareGuidanceScheduler.from_scheduler(
            base_scheduler,
            guidance_update_interval=interval,
        )
        thg_scheduler.reset_statistics()

        # æ¨¡æ‹Ÿæ¨ç†
        for step in range(num_steps):
            should_update = thg_scheduler.should_update_guidance(step)
            noise_cond = torch.randn(1, 4, 64, 64)
            noise_uncond = torch.randn(1, 4, 64, 64) if should_update else None

            thg_scheduler.compute_noise_pred_with_thg(
                noise_cond, noise_uncond, 3.0, step
            )

        stats = thg_scheduler.get_statistics()
        speedup = (num_steps * 2) / stats['total_nfe']
        results.append({
            'interval': interval,
            'nfe': stats['total_nfe'],
            'saved': stats['saved_nfe'],
            'speedup': speedup,
        })

        print(f"  é—´éš”={interval}: NFE={stats['total_nfe']:3d}, åŠ é€Ÿ={speedup:.2f}Ã—, èŠ‚çœ={stats['efficiency']}")

    print(f"\nâœ… æµ‹è¯•2é€šè¿‡: é—´éš”è¶Šå¤§ï¼ŒåŠ é€Ÿè¶Šæ˜æ˜¾")
    print(f"   æ¨è: interval=3 (åŠ é€Ÿ{results[2]['speedup']:.2f}Ã—)")


def test_thg_proxy():
    """æµ‹è¯•THGè°ƒåº¦å™¨å¯¹åŸºç¡€è°ƒåº¦å™¨æ–¹æ³•çš„ä»£ç†"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: THGè°ƒåº¦å™¨å±æ€§ä»£ç†")
    print("=" * 80)

    base_scheduler = DDPMScheduler(
        num_train_timesteps=1000,
        beta_start=0.00085,
    )

    thg_scheduler = TortoiseHareGuidanceScheduler.from_scheduler(
        base_scheduler,
        guidance_update_interval=3,
    )

    # æµ‹è¯•å±æ€§ä»£ç†
    assert thg_scheduler.num_train_timesteps == 1000, "åº”è¯¥ä»£ç†num_train_timesteps"
    assert thg_scheduler.beta_start == 0.00085, "åº”è¯¥ä»£ç†beta_start"

    print(f"  âœ“ num_train_timesteps = {thg_scheduler.num_train_timesteps}")
    print(f"  âœ“ beta_start = {thg_scheduler.beta_start}")

    # æµ‹è¯•set_timestepsæ–¹æ³•
    thg_scheduler.set_timesteps(50)
    assert len(thg_scheduler.timesteps) == 50, "åº”è¯¥ä»£ç†set_timestepsæ–¹æ³•"
    print(f"  âœ“ set_timesteps(50) -> {len(thg_scheduler.timesteps)} timesteps")

    print(f"\nâœ… æµ‹è¯•3é€šè¿‡: THGæ­£ç¡®ä»£ç†åŸºç¡€è°ƒåº¦å™¨çš„æ‰€æœ‰æ–¹æ³•")


def test_weight_symmetry():
    """æµ‹è¯•reconstructorçš„æƒé‡å¯¹ç§°æ€§"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•4: Reconstructoræƒé‡çŸ©é˜µå¯¹ç§°æ€§")
    print("=" * 80)

    # è¯»å–ä¿®å¤åçš„æƒé‡
    weights = torch.Tensor([
        1.0, 0.8, 0.6, 0.5, 0.7, 0.8, 0.7, 0.5, 0.6, 0.8,  # 0-162Â°
        1.0, 0.8, 0.6, 0.5, 0.7, 0.8, 0.7, 0.5, 0.6, 0.8,  # 180-342Â°
    ])

    # æ£€æŸ¥å‰åå¯¹ç§°æ€§ï¼ˆ0Â° vs 180Â°ï¼‰
    front_weight = weights[0]
    back_weight = weights[10]

    print(f"  æ­£å‰æ–¹ (0Â°):   æƒé‡ = {front_weight:.1f}")
    print(f"  æ­£åæ–¹ (180Â°): æƒé‡ = {back_weight:.1f}")

    assert front_weight == back_weight, "å‰åæƒé‡åº”è¯¥ç›¸ç­‰"
    print(f"\n  âœ“ å‰åå¯¹ç§°æ€§æ£€æŸ¥é€šè¿‡")

    # æ£€æŸ¥å·¦å³å¯¹ç§°æ€§ï¼ˆ90Â° vs 270Â°ï¼‰
    right_weight = weights[5]
    left_weight = weights[15]

    print(f"  å³ä¾§ (90Â°):  æƒé‡ = {right_weight:.1f}")
    print(f"  å·¦ä¾§ (270Â°): æƒé‡ = {left_weight:.1f}")

    assert right_weight == left_weight, "å·¦å³æƒé‡åº”è¯¥ç›¸ç­‰"
    print(f"  âœ“ å·¦å³å¯¹ç§°æ€§æ£€æŸ¥é€šè¿‡")

    print(f"\nâœ… æµ‹è¯•4é€šè¿‡: æƒé‡çŸ©é˜µå·²æ­£ç¡®ä¿®å¤ä¸ºå¯¹ç§°")


if __name__ == "__main__":
    try:
        test_thg_basic()
        test_thg_intervals()
        test_thg_proxy()
        test_weight_symmetry()

        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 80)
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®Œæ•´æ¨ç†æµ‹è¯•:")
        print("     python inference_thg.py --data_dir <input> --output_dir <output>")
        print("\n  2. å¯¹æ¯”æ ‡å‡†æ¨ç†å’ŒTHGæ¨ç†çš„è´¨é‡:")
        print("     python inference_low_gpu.py --data_dir <input> --output_dir output_baseline")
        print("     python inference_thg.py --data_dir <input> --output_dir output_thg")
        print("\n  3. æ£€æŸ¥å¤´éƒ¨é¼“åŒ…æ˜¯å¦ä¿®å¤ï¼ˆé‡ç‚¹çœ‹åè„‘å‹ºï¼‰")
        print("=" * 80)

    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        exit(1)
    except Exception as e:
        print(f"\nâŒ è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
